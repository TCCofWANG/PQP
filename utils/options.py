import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--exp-name', type=str, default='exp_0')
parser.add_argument('--model', type=str, default='llama-7b-hf', help='model to load.')
parser.add_argument('--model-name', type=str, default='llama_7b')
parser.add_argument("--sparsity_type", type=str, default="unstructured", choices=["unstructured", "4:8", "2:4"])
parser.add_argument('--sparsity', type=float, default=0.5, help='Target sparsity')
parser.add_argument("--prune-method", type=str,
                    choices=["magnitude", "wanda", "sparsegpt", "ria", "pruner-zero", "dense", "besa", "pqp", "pqp-metric"])
parser.add_argument('--metric-type', type=str, default=None)
parser.add_argument('--quant-type', type=str, default=None)
parser.add_argument('--quant-error-loss', action='store_true')
parser.add_argument("--cache_dir", default="llm_weights", type=str)
parser.add_argument("--eval_zero_shot", action="store_true")
parser.add_argument('--batch-size', type=int, default=1, help='batch size of model evaluation')
parser.add_argument('--save', type=str, default=None, help='Path to save quant weight.')
parser.add_argument('--load', type=str, default=None, help='Path to load quant weight.')
parser.add_argument('--eval-dense', action='store_true', help='Whether to evaluate the dense model')
parser.add_argument('--seed', type=int, default=0, help='Seed for sampling the calibration data.')
parser.add_argument('--nsamples', type=int, default=128, help='Number of calibration data samples.')
parser.add_argument('--save-path', type=str, default=None)
parser.add_argument('--fix-layers', type=str, default=None)
parser.add_argument('--no-dense-loss', action='store_true')
parser.add_argument('--epochs', type=int, default=1)
parser.add_argument('--prune-batch-size', type=int, default=1)
parser.add_argument('--use-fp32', action='store_true')
parser.add_argument('--wise-dim', type=str, default='row')
parser.add_argument('--use_variant', action="store_true", help="whether to use the wanda variant described in the appendix")
# Learning parameter settings
parser.add_argument('--blocksize', type=int, default=-1)
parser.add_argument('--sparsity-step', type=float, default=0.01)
parser.add_argument('--lora-rank', type=int, default=-1)
# Loss settings
parser.add_argument('--sparsity-beta', type=float, default=1)
parser.add_argument('--norm-all', action='store_true')
parser.add_argument('--prune-dense', action='store_true')
parser.add_argument('--l2-alpha', type=float, default=1)
parser.add_argument('--l2-beta', type=float, default=1)
parser.add_argument('--no-sigmoid-smooth', action='store_true')
# Scaler (norm, value) and Scheduler
parser.add_argument('--clip-grad', type=float)
parser.add_argument('--clip-mode', type=str, default='norm')
parser.add_argument('--no-scaler', action='store_true')
parser.add_argument('--use-cos-sche', action='store_true')
# Normal Opt settings (AdamW)
parser.add_argument('--normal-opt', action='store_true')
parser.add_argument('--normal-opt-lr', type=float, default=1e-2)
parser.add_argument('--normal-default', action='store_true')
# Prodigy settings
parser.add_argument('--d-coef', type=float, default=1)
parser.add_argument('--prodigy-lr', type=float, default=1)
parser.add_argument('--no-decouple', action='store_true')
parser.add_argument('--use-bias-correction', action='store_true')
parser.add_argument('--safeguard-warmup', action='store_true')
parser.add_argument('--weight-decay', type=float, default=0)
# gradient_path
parser.add_argument("--gradient_path", type=str, default=None, help="Path to save the gradient.")
# quantizition setting
parser.add_argument("--percdamp", type=float, default=0.01, help="Percent of the average Hessian diagonal to use for dampening.")
parser.add_argument('--true-sequential', action='store_true', help='Whether to run in true sequential model.')
parser.add_argument("--wbits", type=int, default=16, help="#bits to use for quantization; use 16 for evaluating base model.")
parser.add_argument("--groupsize", type=int, default=-1, help="How many weight columns (input features) are quantized with the same statistics, default = all of them")
parser.add_argument('--static-groups', action='store_true', help='Whether to use static groups; recommended when using `--actorder` for more efficient inference.')
parser.add_argument("--sym", action="store_true", help="Symmetric quantization")
parser.add_argument("--perchannel", action="store_true", help="fit a unique quantizer to each output dim")
parser.add_argument('--act-order', action='store_true',help='Whether to apply the activation order GPTQ heuristic')
args = parser.parse_args()